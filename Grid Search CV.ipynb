{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1acfe2df",
   "metadata": {},
   "source": [
    "# Mise en place de la validation croisée avec influence d'hyperparamètre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9aa1b2",
   "metadata": {},
   "source": [
    "## Création des bases de données de stockages d'informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75f1f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "GridSearch=pd.DataFrame(columns=['Modèle','Type','R²','MAE','MSE','RMSE','Temps'])\n",
    "GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70b74e3",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c39b8d5",
   "metadata": {},
   "source": [
    "### Observation des paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd26740",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Pour le model linéaire les paramètres sont les suivants :')\n",
    "Linear.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f87fc35",
   "metadata": {},
   "source": [
    "#### La prédiction par défaut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c58f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def ajout_par_défaut(model,types,Xtrain,Ytrain,Xtest,Ytest,list_models,list_types,list_R2,list_MAE,list_MSE,list_RMSE,temps):\n",
    "\n",
    "    debut = time.process_time()\n",
    "\n",
    "    modele=model.fit(Xtrain, Ytrain)\n",
    "    ypredict = modele.predict(Xtest)\n",
    "    r2=np.round(r2_score(Ytest, ypredict),3)\n",
    "    mae=np.round(mean_absolute_error(Ytest, ypredict),3)\n",
    "    mse=np.round(mean_squared_error(Ytest, ypredict),3)\n",
    "    rmse=np.round(sqrt(mean_squared_error(Ytest, ypredict)),3)\n",
    "\n",
    "    list_models.append(model)\n",
    "    list_types.append(types)\n",
    "    list_R2.append(r2)\n",
    "    list_MAE.append(mae)\n",
    "    list_MSE.append(mse)\n",
    "    list_RMSE.append(rmse)\n",
    "    \n",
    "    fin = time.process_time()\n",
    "    tps=fin-debut\n",
    "    temps.append(tps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e73d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Création des listes de stockages\n",
    "models=[]\n",
    "types=[]\n",
    "list_R2=[]\n",
    "list_MAE=[]\n",
    "list_MSE=[]\n",
    "list_RMSE=[]\n",
    "list_ACC=[]\n",
    "Temps=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f072286f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ajout_par_défaut(Linear,'Par défaut',xtrain_log,ytrain_log,xtest_log,ytest_log,models,types,list_R2,list_MAE,list_MSE,list_RMSE,Temps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f51b453",
   "metadata": {},
   "source": [
    "#### Prediction avec GridSearch cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc81a5ef",
   "metadata": {},
   "source": [
    "Nous allons d'abord chercher quels paramètres nous semblent les plus important pour cette modélisation.\n",
    "\n",
    "    - copy_x, vaut True par défaut, et correspond au fait de faire une copie de notre data set x. Nous ne toucherons pas à ce paramètre.\n",
    "    - Fit_intercept, vaut également True par Défaut, et correspond à la présence ou non d'une ordonnée à l'origine. \n",
    "    - Normalize, à par valeur par défaut False, et correspond au fait de normalisé le dataset X avant la regression par le modèle. Nous ne toucherons pas non plus à ce paramètre, les données étant déjà standardisées.\n",
    "    - Positive, vaut False par défaut. Lorsque ce dernier est True, il force les coefficients à être positifs.\n",
    "    \n",
    "Nous jouerons donc sur fit intercept et positive comme paramètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c90d149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mise en place du dictionnaire des paramètres à tester\n",
    "paramètre={'fit_intercept' :['True','False'],'positive' :['True','False']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38bebfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "Linear_GS=GridSearchCV(estimator =Linear, param_grid=paramètre, cv=5, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cc1ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Linear_GS.fit(xtrain_log,ytrain_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162b9240",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(Linear_GS.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae07e221",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(Linear_GS,open('Linear_GS','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b364654",
   "metadata": {},
   "outputs": [],
   "source": [
    "Linear_GS =  pickle.load(open(\"Linear_GS\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ef747e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(Linear_GS.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e8750e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Linear_GS.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c41786",
   "metadata": {},
   "outputs": [],
   "source": [
    "ajout_par_défaut(LinearRegression(fit_intercept='True',positive='True'),'Grid Search',xtrain_log,ytrain_log,xtest_log,ytest_log,models,types,list_R2,list_MAE,list_MSE,list_RMSE,Temps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6623d2e",
   "metadata": {},
   "source": [
    "## Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff1cc48",
   "metadata": {},
   "source": [
    "### Observation des paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab0e82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "print('Pour le model Ridge les paramètres sont les suivants :')\n",
    "Ridge().get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daaeac23",
   "metadata": {},
   "source": [
    "#### La prédiction par défaut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc0d9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ajout_par_défaut(Ridge(),'Par défaut',xtrain_log,ytrain_log,xtest_log,ytest_log,models,types,list_R2,list_MAE,list_MSE,list_RMSE,Temps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da610b0",
   "metadata": {},
   "source": [
    "#### Prediction avec GridSearch cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9611417c",
   "metadata": {},
   "source": [
    "Nous allons d'abord chercher quels paramètres nous semblent les plus important pour cette modélisation.\n",
    "\n",
    "    - Alpha vaut par défaut 1, c'est le paramètre qui controle la force de régularisation. Il peut varier entre 0 et l'infini, nous jouerons avec ce paramètre.\n",
    "    - copy_x, vaut True par défaut, et correspond au fait de faire une copie de notre data set x. Nous ne toucherons pas à ce paramètre.\n",
    "    - Fit_intercept, vaut également True par Défaut, et correspond à la présence ou non d'une ordonnée à l'origine. Dans notre cas, nous ne toucherons pas non plus à ce paramètre.\n",
    "    - Max_iter, est équivalent à None par défaut, il correspond au nombre d'iteration et dépend du solveur.\n",
    "    - Normalize, à par valeur par défaut False, et correspond au fait de normalisé le dataset X avant la regression par le modèle. Nous ne toucherons pas non plus à ce paramètre, les données étant déjà standardisées.\n",
    "    - Positive, vaut False par défaut. Lorsque ce dernier est True, il force les coefficients à être positifs, nous ne toucherons pas non plus à ce paramètre.\n",
    "    - Solver, vaut par défaut auto, ce qui correspond au fait que le solveur sera choisi automatiquement en fonction du type de données. Nous ne toucherons pas à ce paramètre non plus.\n",
    "    - Tol, vaut 0.001 par défaut et correspond à la précision de la solution. Nous pourrons essayer de jouer avec ce dernier.\n",
    "    \n",
    "Nous jouerons donc sur les paramètres alpha et tol pour ce modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e49b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mise en place du dictionnaire des paramètres à tester\n",
    "paramètre={'alpha' :[1,5,10,15,20],'tol' :[0.0001,0.001,0.01,0.1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b330bfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ridge_GS=GridSearchCV(estimator =Ridge, param_grid=paramètre, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce7b27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ridge_GS.fit(xtrain_log,ytrain_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b32bdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(Ridge_GS,open('Ridge_GS','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e6acd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ridge_GS =  pickle.load(open(\"Ridge_GS\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b22f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ridge_GS.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e26a72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "ajout_par_défaut(Ridge(alpha=20,tol=0.0001,random_state=21),'Grid Search',xtrain_log,ytrain_log,xtest_log,ytest_log,models,types,list_R2,list_MAE,list_MSE,list_RMSE,Temps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08ab725",
   "metadata": {},
   "source": [
    "## KNNR : K neighbors regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1a5ec2",
   "metadata": {},
   "source": [
    "### Observation des paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c897985",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Pour le model K neighbors Regressor les paramètres sont les suivants :')\n",
    "KNNR.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce29fd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "ajout_par_défaut(KNNR,'Par défaut',xtrain_log,ytrain_log,xtest_log,ytest_log,models,types,list_R2,list_MAE,list_MSE,list_RMSE,Temps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c44c5aa",
   "metadata": {},
   "source": [
    "#### Prediction avec GridSearch cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ef5ddc",
   "metadata": {},
   "source": [
    "Nous allons d'abord chercher quels paramètres nous semblent les plus important pour cette modélisation.\n",
    "\n",
    "    - Algorithm prend par défaut la valeur 'auto', prendre cette valeur permet de déterminer le meilleur algorithme selon les valeurs d'entrainement. Nous ne changerons donc pas ce paramètre. \n",
    "    - Le leaf size, impact la vitesse d'execution et la mémoire, nous n'influerons donc pas non plus sur ce paramètre. \n",
    "    - Metric, se base sur la manière dont est mesurée la distance entre les points et la prédiction. Par défaut il s'agit de la distance euclidienne standard lorsque p vaut 2. Nous n'influerons pas sur ce paramètre. \n",
    "    - Metric params, il s'agit de paramètre additionnel pour la mise en place de la metrics et correspond à un dictionnaire, la valeur par défaut est None et nous ne changerons pas cela ici. \n",
    "    - N_neighbors, prend 5 comme valeur par défaut, mais peut changer et c'est ce que nous ferons ici. \n",
    "    - P correspond à la puissance de la valeur du paramètre par défaut de metrics, et peut donc influencer ce dernier en prenant la valeur 1 ou 2.\n",
    "    - Weights, par défaut les voisins pèsent le même poids dans les predictions, nous allons donc influer sur ce paramètre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97456203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mise en place du dictionnaire des paramètres à tester\n",
    "paramètre={'n_neighbors' :[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],'p' :[1,2],'weights':('uniform', 'distance')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85ac7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNNR_GS=GridSearchCV(estimator =KNNR, param_grid=paramètre, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e864eb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNNR_GS.fit(xtrain_log,ytrain_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099d9c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(KNNR_GS,open('KNNR_GS','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b3b674",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNNR_GS=pickle.load(open(\"KNNR_GS\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1e4cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNNR_GS.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141eec5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ajout_par_défaut(KNeighborsRegressor(n_neighbors= 8, p= 1, weights= 'uniform', n_jobs=1),'Grid Search',xtrain_log,ytrain_log,xtest_log,ytest_log,models,types,list_R2,list_MAE,list_MSE,list_RMSE,Temps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b896ac3",
   "metadata": {},
   "source": [
    "## SVR : Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2d9446",
   "metadata": {},
   "source": [
    "### Observation des paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f2cf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Pour le model SVR les paramètres sont les suivants :')\n",
    "Svr.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81adb776",
   "metadata": {},
   "source": [
    "#### La prédiction par défaut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb0fa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "ajout_par_défaut(Svr,'Par défaut',xtrain_log,ytrain_log,xtest_log,ytest_log,models,types,list_R2,list_MAE,list_MSE,list_RMSE,Temps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875ca9a7",
   "metadata": {},
   "source": [
    "#### Prediction avec GridSearch cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6718462",
   "metadata": {},
   "source": [
    "Nous allons d'abord chercher quels paramètres nous semblent les plus important pour cette modélisation. \n",
    "\n",
    "    Le paramètre C correspond à la régularisation, plus C est faible plus la force de régularisation est forte et par conséquent le model va lisser le résultat. Par défault il vaut 1.\n",
    "    Le cache_size correspond à la mémoire cache, nous n'allons pas jouer avec ce paramètre.\n",
    "    Le coef 0, est significatif que pour les kernels poly et sigmoid que nous n'utiliserons pas ici. \n",
    "    Le degree, est utilisé pour le kernel de type poly, ce que nous n'utiliserons pas ici.\n",
    "    Espilon, il spécifie le tube epsilon à l'intérieur duquel aucune pénalité n'est associée dans la fonction de perte d'apprentissage aux points prédits à une distance epsilon de la valeur réelle. Par défaut il vaut 0.1, nous allons voir si cela impacte les résultats de notre model.\n",
    "    Gamma, correspond au coefficient de kernel et est surtout utilisé pour rbf poly et sigmoid. Nous allons donc influer sur ce paramètre qui peut prendre la valeur auto ou scale(valeur par défaut).\n",
    "    Kernel, nous allons d'après la carte scikit learn utilise rbf et linear. \n",
    "    Max_iter, correspond à la limite stricte pour le nombre d'itération. Il vaut -*1 par défaut ce qui signifie pas de limite. Nous n'influrons pas sur     verbose\n",
    "\n",
    "Nous influerons donc sur les paramètres C, Epsilon, gamma, et kernel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b844c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "paramètres={'C' :[1,5,10],'epsilon' :[0.05,0.1,0.5],'gamma':('auto','scale'),'kernel' : ('linear', 'rbf')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09c73a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVR_GS=GridSearchCV(estimator =SVR(), param_grid=paramètres, cv=5, verbose = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ad2596",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVR_GS.fit(xtrain_log,ytrain_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687e5cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(SVR_GS,open('SVR_GS','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037b7ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVR_GS=pickle.load(open(\"SVR_GS\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9808708a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVR_GS.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daab57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af61ebe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ajout_par_défaut(SVR(C= 10, epsilon= 0.1, gamma= 'auto', kernel= 'rbf'),'Grid Search',xtrain_log,ytrain_log,xtest_log,ytest_log,models,types,list_R2,list_MAE,list_MSE,list_RMSE,Temps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69968b6",
   "metadata": {},
   "source": [
    "## Random Forest Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b57ae6",
   "metadata": {},
   "source": [
    "### Observation des paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1305a4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Pour le model Random Forest Regressor les paramètres sont les suivants :')\n",
    "Random_Forest_Regressor.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4447e308",
   "metadata": {},
   "source": [
    "#### La prédiction par défaut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966c1b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "ajout_par_défaut(Random_Forest_Regressor,'Par défaut',xtrain_log,ytrain_log,xtest_log,ytest_log,models,types,list_R2,list_MAE,list_MSE,list_RMSE,Temps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7f7eb1",
   "metadata": {},
   "source": [
    "#### Prediction avec GridSearch cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdd355d",
   "metadata": {},
   "source": [
    "Nous allons d'abord chercher quels paramètres nous semblent les plus important pour cette modélisation. \n",
    "\n",
    "    - Bootstrap, prend vrai comme valeur par défaut, afin de découper le dataset en différentes parties. Nous ne changerons pas ce paramètre. \n",
    "    - ccp alpha, permet de faire une selection d'une sous arborescence en fonction de son cout de complexité et de sa taille. Nous ne toucherons pas ce paramètre ici. \n",
    "    - Criterion permet de mesurer, la qualite de fractionnement, nous ne toucherons pas non plus ce paramètre. \n",
    "    - Max_depth, correspond au nombre de noeuds et donc à la profondeur de l'arbre. Par défaut, il prend la valeur maximale selon le min sample split donné. \n",
    "    - Max-features, correspond au nombre maximum de feature à prendre en compte pour la recherche de la meilleure répartition. Il vaut 1 par défaut, et correspond alors au n features\n",
    "    - Max_leaf_nodes, prend None comme valeur par défaut, qui correspond au faut que ce nombre soit illimité. \n",
    "    - Max sample, prends None par défaut, il correspond au nombre d'échantillon à sortir de X train pour entrainer le modele.\n",
    "    - Min impurity decrease, prend 0 par défaut, le fractionnement d'un noeud aura lieu si l'impureté de ce dernier est meilleur ou équivalent à cette valeur. Nous ne toucherons pas à cette valeur\n",
    "    - Min_samples_leaf, correspond au fait qu'un noeud ne pourra exister que si le nombre d'échantillon sortant après le fractionnement est égal à cette valeur. Il vaut 1 par défaut et nous ne toucherons pas à ce paramètre. \n",
    "    - Min_samples_split, vaut 2 par défaut, et correspond, au nombre d'échantillon minimum pour fractionner un noeud. \n",
    "    - Min_weight_fraction_leaf, vaut 0 par défaut, et correspond à la fraction minimum du poids du fractionnement sur la somme des poids des différents fractionnement demandé pour être à un noeud. Lorsque ce paramètre n'est pas rempli, cela veut dire que les poids sont tous égaux. Nous ne toucherons pas à ce paramètre ici. \n",
    "    - n_estimator vaut 100 par défaut, et correspond, au nombre d'arbre dans la foret. Nous jouerons sur ce paramètre.\n",
    "    - oob_score, est faux par défaut, et permet d'estimer le score générale à partir des échantillons non utilisée. Nous ne jouerons pas avec ce paramètre ici. \n",
    "    - Warm start est faux par défaut, et permet d'utiliser la solution précédente pour fit les données dans le modèle. Nous ne toucherons pas à ce paramètre.\n",
    "\n",
    "Nous jouerons donc sur le n estimator, le min sample split (qui influera sur le max depth) et le nombre de feature maximale. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bb3180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mise en place du dictionnaire des paramètres à tester\n",
    "paramètre={'n_estimators' :[50,100,150,200,250,300,350,400,450,500],'min_samples_split' :[2,3,4,5,6,7,8,9,10],'max_features':(1,'sqrt','log2')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebac0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "RFR_GS=GridSearchCV(estimator =Random_Forest_Regressor, param_grid=paramètre, cv=5, verbose =3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb417528",
   "metadata": {},
   "outputs": [],
   "source": [
    "RFR_GS.fit(xtrain_log,ytrain_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd51acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(RFR_GS,open('RFR_GS','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f8039e",
   "metadata": {},
   "outputs": [],
   "source": [
    "RFR_GS=pickle.load(open(\"RFR_GS\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81759b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "RFR_GS.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23486f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "ajout_par_défaut(RandomForestRegressor(n_estimators = 500, max_features = 'sqrt', min_samples_split =8, random_state=21),'Grid Search',xtrain_log,ytrain_log,xtest_log,ytest_log,models,types,list_R2,list_MAE,list_MSE,list_RMSE,Temps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06227e7e",
   "metadata": {},
   "source": [
    "## Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfa508a",
   "metadata": {},
   "source": [
    "### Observation des paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ae7fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Pour le model Gradient Boosting Regressor les paramètres sont les suivants :')\n",
    "Gradient_Boosting_Regressor.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69da6654",
   "metadata": {},
   "source": [
    "#### La prédiction par défaut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3294a8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ajout_par_défaut(Gradient_Boosting_Regressor,'Par défaut',xtrain_log,ytrain_log,xtest_log,ytest_log,models,types,list_R2,list_MAE,list_MSE,list_RMSE,Temps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43369e79",
   "metadata": {},
   "source": [
    "#### Prediction avec GridSearch cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f0dcea",
   "metadata": {},
   "source": [
    "Nous allons d'abord chercher quels paramètres nous semblent les plus important pour cette modélisation. \n",
    "\n",
    "    - Alpha est lié au loss il doit être compris entre 0 et 1 si le loss vaut huber ou quantile. \n",
    "    - ccp alpha, permet de faire une selection d'une sous arborescence en fonction de son cout de complexité et de sa taille. Nous ne toucherons pas ce paramètre ici. \n",
    "    - Criterion permet de mesurer, la qualite de fractionnement, nous ne toucherons pas non plus ce paramètre. \n",
    "    - Init, il vaut None par défaut. Permet de calculer les prediction initial via fit et predict, nous ne l'utiliserons pas ici. \n",
    "    - learning_rate, vaut 0.1 par défaut et correspond au taux d'appretissage de l'arbre. Il est lié au n_estimator. Nous jouerons sur ce paramètre. \n",
    "    - loss, vaut squarred error par défaut. Il sert à optimiser la fonction de perte par la mesure d'un paramètre statistique, par défaut le squared error. Nous ne toucherons pas à ce paramètre ici. \n",
    "    - max_depth, vaut 3 par défaut et correspond au nombre de noeud dans l'arbre. Nous jouerons donc sur ce dernier.\n",
    "    - Max-features, correspond au nombre maximum de feature à prendre en compte pour la recherche de la meilleure répartition. Il vaut None par défaut, et correspond alors au n features.\n",
    "    - Max_leaf_nodes, prend None comme valeur par défaut, qui correspond au fait que ce nombre soit illimité. \n",
    "    - Min impurity decrease, prend 0 par défaut, le fractionnement d'un noeud aura lieu si l'impureté de ce dernier est meilleur ou équivalent à cette valeur. Nous ne toucherons pas à cette valeur\n",
    "    - Min_samples_leaf, correspond au fait qu'un noeud ne pourra exister que si le nombre d'échantillon sortant après le fractionnement est égal à cette valeur. Il vaut 1 par défaut et nous ne toucherons pas à ce paramètre. \n",
    "    - Min_samples_split, vaut 2 par défaut, et correspond, au nombre d'échantillon minimum pour fractionner un noeud. Il peut prendre des valeurs entre 2 et l'infini.\n",
    "    - Min_weight_fraction_leaf, vaut 0 par défaut, et correspond à la fraction minimum du poids du fractionnement sur la somme des poids des différents fractionnement demandé pour être à un noeud. Lorsque ce paramètre n'est pas rempli, cela veut dire que les poids sont tous égaux. Il prends des valeurs entre 0 et 0,5. Nous ne toucherons pas à ce paramètre ici. \n",
    "    - n_estimators vaut 100 par défaut et correspond au nombre d'étapes qui doivent se dérouler au sein du modèle. Il peut aller de 1 à l'infini. Nous jouerons avec ce paramètre.\n",
    "    - n_iter_no_change, vaut None par défaut, et est utilisé pour décidé de mettre fin au modèle lorsque le score de validation ne s'améliore plus. Lorsqu'il est un nombre, il défini la taille de l'échantillon d'apprentissage sur le score en question sera vérifié. Les valeurs vont de 1 à l'infini. Nous jouerons sur ce paramètre. \n",
    "    - Subsample, vaut 0 par défaut. Et correspond à la fraction des échantillons qui doivent être utilisé pour l'ajustement des apprenants de base individuels. Les valeurs peuvent aller de 0 à 1, 1 reduisant la variance et augmentant le biais le plus.\n",
    "    - Tol vaut 1e-4 par défaut, et correspond, à la tolérance pour l'arret avancé du modèle. Ce paramètre est lié à no iter no change. L'arret du modèle à lieu si la perte ne s'améliore pas d'au moins la valeur choisie. \n",
    "    - Validation fraction, vaut 0.1 par défaut et correspond à la proportion du dataset qui servira de validation pour arreter le modèle dans le cas ou celui ci ne voit pas son score ni sa perte s'améliorer. Il varie entre 0 et 1.\n",
    "    - Warm start est faux par défaut, et permet d'utiliser la solution précédente pour fit les données dans le modèle. Nous ne toucherons pas à ce paramètre.\n",
    "\n",
    "Nous jouerons sur les paramètres suivants : learning rate, max_depth, max features, min sample split, n_estimators, n_iter no change, validation fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd473be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "paramètre={'learning_rate' :[0.01,0.1,0.25],'max_depth' :[1,3,5,7],'max_features':(1,'sqrt','log2'),'min_samples_split' : [9,10,11,12,13,14], 'n_estimators' :[100,500,1000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38365d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "GBR_GS=GridSearchCV(estimator =Gradient_Boosting_Regressor, param_grid=paramètre, cv=5, verbose = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2587cdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "GBR_GS.fit(xtrain_log,ytrain_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35409dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(GBR_GS,open('GBR_GS','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a364dd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "GBR_GS=pickle.load(open(\"GBR_GS\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ccde99",
   "metadata": {},
   "outputs": [],
   "source": [
    "GBR_GS.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ec1dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ajout_par_défaut(GradientBoostingRegressor(learning_rate= 0.1, max_depth= 7, max_features= 'sqrt', min_samples_split= 11, n_estimators= 500, random_state=21),'Grid Search',xtrain_log,ytrain_log,xtest_log,ytest_log,models,types,list_R2,list_MAE,list_MSE,list_RMSE,Temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f78ef96",
   "metadata": {},
   "outputs": [],
   "source": [
    "GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2271445f",
   "metadata": {},
   "outputs": [],
   "source": [
    "GridSearch['Modèle']=models\n",
    "GridSearch['Type']=types\n",
    "GridSearch['R²']=list_R2\n",
    "GridSearch['MAE']=list_MAE\n",
    "GridSearch['MSE']=list_MSE\n",
    "GridSearch['RMSE']=list_RMSE\n",
    "GridSearch['Temps']=Temps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088f1abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cde7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "Au vu des résultats obtenu par le Grid Search CV, et de la taille de notre dataset à traiter, nous allons nous orienter vers le Gradient Boosting regressor avec les paramètres suivants : 'learning_rate': 0.1, 'max_depth': 7, 'max_features': 'sqrt','min_samples_split': 11, 'n_estimators': 500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593b8b03",
   "metadata": {},
   "source": [
    "# Observation du modèle choisi de manière graphique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32bad5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "modele=GradientBoostingRegressor(learning_rate= 0.1, max_depth= 7, max_features= 'sqrt', min_samples_split= 11, n_estimators= 500, random_state=21)\n",
    "fit=modele.fit(xtrain_log,ytrain_log)\n",
    "ypredict_log=fit.predict(xtest_log)\n",
    "# Visualisation du modèle prédit selon les valeurs test\n",
    "sns.regplot(x=ypredict_log,y=ytest_log)\n",
    "# Obtenir la ligne correspondant au valeur test\n",
    "plt.plot(ytest_log,ytest_log)\n",
    "plt.xlabel(\"Tm - Prediction (blue)\")\n",
    "plt.ylabel(\"Tm - Prediction (orange)\")\n",
    "plt.title(\"Tm - Prediction vs Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff6605c",
   "metadata": {},
   "source": [
    "On voit ainsi, que les droites orange et bleue sont assez proches et que le nuage de points est centré au niveau du croisement de ces deux droites. Passons maintenant à une analyse du feature importance afin de constater l'impact de notre feature engineering sur nos résultats."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
